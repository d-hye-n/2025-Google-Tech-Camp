{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "8b82e5ae7af840e486a9ce4cd0069575": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b205535376d44ac2b2c3a5e8e18244a1",
       "IPY_MODEL_c3192cb0fd164a2e9167242ecc9df7f3",
       "IPY_MODEL_cf2a26cf9bbb442eb84369aea35218f8"
      ],
      "layout": "IPY_MODEL_d537793a3306450d8d754241ad87a624"
     }
    },
    "b205535376d44ac2b2c3a5e8e18244a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f161de9ff93740d0ad12a85c9a522c7f",
      "placeholder": "​",
      "style": "IPY_MODEL_f7ce89b7cfc84940a375c93056b1e40c",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "c3192cb0fd164a2e9167242ecc9df7f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_503a2cc6240d4966916f2c247f2b5ebd",
      "max": 1182,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_650803c90d8b4b01b71787a0a4205577",
      "value": 1182
     }
    },
    "cf2a26cf9bbb442eb84369aea35218f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b6430a5492243dd949ab7ad7dcf9547",
      "placeholder": "​",
      "style": "IPY_MODEL_8c38087ba1814ecbb0880f4433176b3a",
      "value": " 1.18k/1.18k [00:00&lt;00:00, 99.5kB/s]"
     }
    },
    "d537793a3306450d8d754241ad87a624": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f161de9ff93740d0ad12a85c9a522c7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7ce89b7cfc84940a375c93056b1e40c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "503a2cc6240d4966916f2c247f2b5ebd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "650803c90d8b4b01b71787a0a4205577": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b6430a5492243dd949ab7ad7dcf9547": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c38087ba1814ecbb0880f4433176b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b433833c4bd4e7db4eadebd9abf3243": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2a1af9911df450c8be4c7cba1afd63d",
       "IPY_MODEL_e08a7ad43c6e4bc4af9630b411a431d0",
       "IPY_MODEL_3373f6c2f29e4031934b5c1e8a51fd7a"
      ],
      "layout": "IPY_MODEL_118dea90401f44df8d464b74e801315e"
     }
    },
    "f2a1af9911df450c8be4c7cba1afd63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6bc3334ce584424bee582dad798dbbc",
      "placeholder": "​",
      "style": "IPY_MODEL_0d2ef7b4bf1541f19df48aa8fba452ed",
      "value": "sentencepiece.bpe.model: 100%"
     }
    },
    "e08a7ad43c6e4bc4af9630b411a431d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d111b5fb03074335add9d7d9a58a8841",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7877ae4f4545453a9a9ffacc20a11aa2",
      "value": 5069051
     }
    },
    "3373f6c2f29e4031934b5c1e8a51fd7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0282ecef30594b62a2e018d787558725",
      "placeholder": "​",
      "style": "IPY_MODEL_fe6cabead21b47a886d5c0db560c6971",
      "value": " 5.07M/5.07M [00:00&lt;00:00, 61.7MB/s]"
     }
    },
    "118dea90401f44df8d464b74e801315e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6bc3334ce584424bee582dad798dbbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2ef7b4bf1541f19df48aa8fba452ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d111b5fb03074335add9d7d9a58a8841": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7877ae4f4545453a9a9ffacc20a11aa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0282ecef30594b62a2e018d787558725": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe6cabead21b47a886d5c0db560c6971": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a645d3ba3b2840a392bf5f778dd1a2c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47f20d56b1ef4f9495ac1916a9393873",
       "IPY_MODEL_d7e4ee31dcb84cf29865a4f78e22edfa",
       "IPY_MODEL_ba9394607d044b6dab277e181c547778"
      ],
      "layout": "IPY_MODEL_911aa874591a48829e35e6aaf774521f"
     }
    },
    "47f20d56b1ef4f9495ac1916a9393873": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a205af143f44735998ee4ee4e437a19",
      "placeholder": "​",
      "style": "IPY_MODEL_6d1321017d264ec39aaa3d8cc16b9f67",
      "value": "tokenizer.json: 100%"
     }
    },
    "d7e4ee31dcb84cf29865a4f78e22edfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cc6d8fadf1740a0b9788b24fa860154",
      "max": 17082756,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07188324250a42b7ac6c03470521f0e7",
      "value": 17082756
     }
    },
    "ba9394607d044b6dab277e181c547778": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5988197d94b14fad996c02c5c36a3681",
      "placeholder": "​",
      "style": "IPY_MODEL_395a959bb82d4887bcb446af01652bd1",
      "value": " 17.1M/17.1M [00:00&lt;00:00, 214MB/s]"
     }
    },
    "911aa874591a48829e35e6aaf774521f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a205af143f44735998ee4ee4e437a19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d1321017d264ec39aaa3d8cc16b9f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0cc6d8fadf1740a0b9788b24fa860154": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07188324250a42b7ac6c03470521f0e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5988197d94b14fad996c02c5c36a3681": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "395a959bb82d4887bcb446af01652bd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4ea2866c2364a11b71271993df573b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_107f2ae38a934e589b08c10edb9a1a5b",
       "IPY_MODEL_384c66319f4146f8ba15f05c058c4367",
       "IPY_MODEL_6bc15052913c441dbe19c08a7697884a"
      ],
      "layout": "IPY_MODEL_80410a641ae44829a542489f525766f4"
     }
    },
    "107f2ae38a934e589b08c10edb9a1a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d36d9a49cb48f99f790d003291e850",
      "placeholder": "​",
      "style": "IPY_MODEL_a5b3a90a4cb5465c91b92d21ba8e5ba2",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "384c66319f4146f8ba15f05c058c4367": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4449cc76d86f4b7989eb35eef5357e58",
      "max": 964,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_60c039f0656b40c4874ddf4a2431f401",
      "value": 964
     }
    },
    "6bc15052913c441dbe19c08a7697884a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_174bdda506b543e9a7c1ba747c304860",
      "placeholder": "​",
      "style": "IPY_MODEL_dabf6c75aca646a981839821d58f15ae",
      "value": " 964/964 [00:00&lt;00:00, 83.7kB/s]"
     }
    },
    "80410a641ae44829a542489f525766f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69d36d9a49cb48f99f790d003291e850": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5b3a90a4cb5465c91b92d21ba8e5ba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4449cc76d86f4b7989eb35eef5357e58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60c039f0656b40c4874ddf4a2431f401": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "174bdda506b543e9a7c1ba747c304860": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dabf6c75aca646a981839821d58f15ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "colab 런타임 : T4"
   ],
   "metadata": {
    "id": "Bx0RZiImzY4X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 Indexing - Loader 실습"
   ],
   "metadata": {
    "id": "9OPdIAPDe25D"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "실습에 활용할 파일 업로드"
   ],
   "metadata": {
    "id": "Y7i64eY5h3aY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "\n",
    "TEST_DATA_PATH = './data'\n",
    "\n",
    "f = files.upload(TEST_DATA_PATH)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "GjGn39n2h1lQ",
    "outputId": "66bb94d2-74c5-4156-fe30-eeddf669285c",
    "ExecuteTime": {
     "end_time": "2025-07-26T07:46:49.141697Z",
     "start_time": "2025-07-26T07:46:48.233226Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgoogle\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcolab\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m files\n\u001B[32m      3\u001B[39m TEST_DATA_PATH = \u001B[33m'\u001B[39m\u001B[33m./data\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      5\u001B[39m f = files.upload(TEST_DATA_PATH)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'google.colab'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "업로드한 파일이 제대로 존재하는지 체크"
   ],
   "metadata": {
    "id": "xcu9BAOlk0ko"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def list_file_info(\n",
    "    dir_path: str, ext: str | None = None, depth: int = 0\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    지정한 directory 의 경로 내에 존재하는 파일정보를 가져오는 함수\n",
    "\n",
    "    :param dir_path: directory 의 경로\n",
    "    :param ext: 가져올 파일의 확장자, 미지정시 전체\n",
    "    :param depth: 탐색 깊이, default = 0, 모든 depth 탐색은 -1로 지정\n",
    "    \"\"\"\n",
    "    info_list = []\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        # 존재하는 파일인지 check\n",
    "        if os.path.isfile(os.path.join(dir_path, file_name)):\n",
    "            if ext is None:\n",
    "                info_list.append(\n",
    "                    {\n",
    "                        \"path\": os.path.join(dir_path, file_name),\n",
    "                        \"name\": os.path.splitext(file_name)[0],\n",
    "                        \"ext\": file_name.split(\".\")[-1],\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                if file_name.lower().endswith(\".\" + ext):\n",
    "                    info_list.append(\n",
    "                        {\n",
    "                            \"path\": os.path.join(dir_path, file_name),\n",
    "                            \"name\": os.path.splitext(file_name)[0],\n",
    "                            \"ext\": file_name.split(\".\")[-1],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        elif os.path.isdir(os.path.join(dir_path, file_name)):\n",
    "            if depth == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # case 1: depth 가 -1 일 경우 모든 dir 를 순회\n",
    "                # case 2: depth 가 1 이상일 경우 최대 depth 값 만큼의 깊이로 재귀호출됨\n",
    "                info_list += list_file_info(\n",
    "                    os.path.join(dir_path, file_name), ext, depth - 1\n",
    "                )\n",
    "\n",
    "    return list(filter(lambda i: not i[\"name\"].startswith(\"~$\"), info_list))\n",
    "\n",
    "file_info_list = list_file_info(TEST_DATA_PATH, ext=\"pdf\")\n",
    "\n",
    "for idx, file_info in enumerate(file_info_list):\n",
    "  print(f\"{idx+1}. {file_info['path'].replace(TEST_DATA_PATH+'/', '')}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNZXcdp6jakL",
    "outputId": "d418c1bc-3355-4a58-a176-60272a1fd386"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1. A4_멀티모달AI생성모델.pdf\n",
      "2. A1_반도체.pdf\n",
      "3. A7_EmbodiedAI구현기술.pdf\n",
      "4. A3_멀티모달기술.pdf\n",
      "5. A5_연합학습.pdf\n",
      "6. A2_컴퓨팅방식.pdf\n",
      "7. A6_EmbodiedAI개념.pdf\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain_community pymupdf"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "d1ARHGOgqa_y",
    "outputId": "5d2f5f27-cd1a-4e9b-dcd0-40330da48a6e"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.44)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.13)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m85.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.0/20.0 MB\u001B[0m \u001B[31m88.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.9/50.9 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, pymupdf, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 pymupdf-1.25.4 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_file_txt_list: list[list[Document]] = []\n",
    "\n",
    "for file_info in file_info_list:\n",
    "  loader = PyMuPDFLoader(file_info[\"path\"])\n",
    "  load_file_txt_list.append(loader.load())\n",
    "\n",
    "# 1번째 file 의 1번째 페이지 파싱 결과\n",
    "print('전처리 전:\\n'+load_file_txt_list[0][0].page_content[:200])\n",
    "\n",
    "# 전처리 추출 결과를 확인해보니깐, 불필요한 문자가 포함되어 있는 것을 확인 (예: 페이지 번호 등)\n",
    "# 이를 제거합니다.\n",
    "# 이 코드는 제공한 데이터셋에 특화된 전처리 코드이므로 다른 데이터를 활용할 경우 비활성화 해주세요\n",
    "\n",
    "filter_texts = [\"THE AI REPORT 2024-1 | 2024. 7. 25.\\n\", \"2024년 AI 이슈를 용어와 함께 쉽게 이해하기\\n\"]\n",
    "\n",
    "for page_txt_list in load_file_txt_list:\n",
    "  for page_txt in page_txt_list:\n",
    "    text = page_txt.page_content\n",
    "    for filter_text in filter_texts:\n",
    "      if text.find(filter_text):\n",
    "        text = text.replace(filter_text, '')\n",
    "\n",
    "    text = \"\\n\".join(text.split('\\n')[2:])\n",
    "    page_txt.page_content = text\n",
    "\n",
    "# 제거 결과 확인\n",
    "print()\n",
    "print('전처리 후:\\n'+load_file_txt_list[0][0].page_content[:200])"
   ],
   "metadata": {
    "id": "tyb3VmqqqnDa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aad32e8e-5904-49c8-c242-9af72f123245"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "전처리 전:\n",
      "THE AI REPORT 2024-1 | 2024. 7. 25.\n",
      "38\n",
      "2. 멀티모달 AI 생성 모델(주요 생성형 AI 모델)\n",
      "2.1. 트랜스포머(Transformer): 멀티모달 AI의 언어 천재, 문맥을 파악하여 맥락 있는 결과를 생성하다\n",
      "① 왜 나오게 되었는가?\n",
      "트랜스포머는 인공지능이 언어를 더 잘 이해하고 생성할 수 있도록 하기 위해 등장했다. 이전의\n",
      "\n",
      "전처리 후:\n",
      "2. 멀티모달 AI 생성 모델(주요 생성형 AI 모델)\n",
      "2.1. 트랜스포머(Transformer): 멀티모달 AI의 언어 천재, 문맥을 파악하여 맥락 있는 결과를 생성하다\n",
      "① 왜 나오게 되었는가?\n",
      "트랜스포머는 인공지능이 언어를 더 잘 이해하고 생성할 수 있도록 하기 위해 등장했다. 이전의 자연어 처리 \n",
      "모델은 RNN(순환 신경망, Recurrent Neur\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 Indexing - Chunking 실습"
   ],
   "metadata": {
    "id": "5eKLkFvcfClw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain_huggingface"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-tMt_ryYyaDS",
    "outputId": "ba740bba-aa4e-4efc-fb20-b3c63b644fb4"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.3.44)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (3.4.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.48.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.10.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m110.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m77.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m51.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m2.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m12.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m94.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langchain_huggingface\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed langchain_huggingface-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large-instruct\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "referenced_widgets": [
      "8b82e5ae7af840e486a9ce4cd0069575",
      "b205535376d44ac2b2c3a5e8e18244a1",
      "c3192cb0fd164a2e9167242ecc9df7f3",
      "cf2a26cf9bbb442eb84369aea35218f8",
      "d537793a3306450d8d754241ad87a624",
      "f161de9ff93740d0ad12a85c9a522c7f",
      "f7ce89b7cfc84940a375c93056b1e40c",
      "503a2cc6240d4966916f2c247f2b5ebd",
      "650803c90d8b4b01b71787a0a4205577",
      "1b6430a5492243dd949ab7ad7dcf9547",
      "8c38087ba1814ecbb0880f4433176b3a",
      "8b433833c4bd4e7db4eadebd9abf3243",
      "f2a1af9911df450c8be4c7cba1afd63d",
      "e08a7ad43c6e4bc4af9630b411a431d0",
      "3373f6c2f29e4031934b5c1e8a51fd7a",
      "118dea90401f44df8d464b74e801315e",
      "b6bc3334ce584424bee582dad798dbbc",
      "0d2ef7b4bf1541f19df48aa8fba452ed",
      "d111b5fb03074335add9d7d9a58a8841",
      "7877ae4f4545453a9a9ffacc20a11aa2",
      "0282ecef30594b62a2e018d787558725",
      "fe6cabead21b47a886d5c0db560c6971",
      "a645d3ba3b2840a392bf5f778dd1a2c7",
      "47f20d56b1ef4f9495ac1916a9393873",
      "d7e4ee31dcb84cf29865a4f78e22edfa",
      "ba9394607d044b6dab277e181c547778",
      "911aa874591a48829e35e6aaf774521f",
      "1a205af143f44735998ee4ee4e437a19",
      "6d1321017d264ec39aaa3d8cc16b9f67",
      "0cc6d8fadf1740a0b9788b24fa860154",
      "07188324250a42b7ac6c03470521f0e7",
      "5988197d94b14fad996c02c5c36a3681",
      "395a959bb82d4887bcb446af01652bd1",
      "e4ea2866c2364a11b71271993df573b3",
      "107f2ae38a934e589b08c10edb9a1a5b",
      "384c66319f4146f8ba15f05c058c4367",
      "6bc15052913c441dbe19c08a7697884a",
      "80410a641ae44829a542489f525766f4",
      "69d36d9a49cb48f99f790d003291e850",
      "a5b3a90a4cb5465c91b92d21ba8e5ba2",
      "4449cc76d86f4b7989eb35eef5357e58",
      "60c039f0656b40c4874ddf4a2431f401",
      "174bdda506b543e9a7c1ba747c304860",
      "dabf6c75aca646a981839821d58f15ae"
     ]
    },
    "collapsed": true,
    "id": "TUO3UllCyt7f",
    "outputId": "606c3486-e88e-4043-cf6d-cc93c0a3623f"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b82e5ae7af840e486a9ce4cd0069575"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b433833c4bd4e7db4eadebd9abf3243"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a645d3ba3b2840a392bf5f778dd1a2c7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4ea2866c2364a11b71271993df573b3"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 125\n",
    "\n",
    "# splitter 생성\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    length_function=lambda x: len(tokenizer(x)[\"input_ids\"]),\n",
    ")\n",
    "\n",
    "split_text_list = []\n",
    "\n",
    "for page_txt_list in load_file_txt_list:\n",
    "    page_cnt = len(page_txt_list)\n",
    "    split_texts = splitter.split_documents(page_txt_list)\n",
    "    split_text_list.append(split_texts)\n",
    "    print(f\"페이지 수: {len(page_txt_list)} -> 청크 수: {len(split_texts)}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVi19mfC0ACz",
    "outputId": "bda53062-295f-4a1e-ae99-445c439760b8"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "페이지 수: 5 -> 청크 수: 10\n",
      "페이지 수: 7 -> 청크 수: 13\n",
      "페이지 수: 6 -> 청크 수: 11\n",
      "페이지 수: 6 -> 청크 수: 11\n",
      "페이지 수: 4 -> 청크 수: 7\n",
      "페이지 수: 4 -> 청크 수: 7\n",
      "페이지 수: 5 -> 청크 수: 10\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for id in range(0, 5):\n",
    "  print('\\n==== 청킹 결과 ('+str(id)+'번) ====:\\n'+split_text_list[0][id].page_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8k2liTd4Sju",
    "outputId": "ba9a6d05-4ba0-402a-927f-4ab70ee92ee8"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "==== 청킹 결과 (0번) ====:\n",
      "2. 멀티모달 AI 생성 모델(주요 생성형 AI 모델)\n",
      "2.1. 트랜스포머(Transformer): 멀티모달 AI의 언어 천재, 문맥을 파악하여 맥락 있는 결과를 생성하다\n",
      "① 왜 나오게 되었는가?\n",
      "트랜스포머는 인공지능이 언어를 더 잘 이해하고 생성할 수 있도록 하기 위해 등장했다. 이전의 자연어 처리 \n",
      "모델은 RNN(순환 신경망, Recurrent Neural Network)이라는 방식을 사용했는데, 이는 마치 책을 한 문장씩 \n",
      "차례대로 읽어나가는 것과 비슷했다. 이 방식은 긴 문장을 이해하는 데 어려움이 있었고, 처리 속도도 느렸다. \n",
      "예를 들어, “나는 어제 친구와 함께 영화를 보았다. 그것은 정말 재미있었다.”라는 문장에서 “그것”이 무엇을 가\n",
      "리키는지 파악하는 데 어려움이 있었다. 트랜스포머는 이러한 문제를 해결하고, 더 나아가 텍스트뿐만 아니라 \n",
      "이미지, 음성 등 다양한 형태의 데이터를 함께 처리할 수 있는 멀티모달 AI의 기반을 발전 및 고도화시킨다.\n",
      "② 쉽게 설명하면?\n",
      "트랜스포머는 문장 전체를 한 번에 이해하는 인공지능 모델이다. 이는 마치 사람이 문장을 읽을 때 전체적인 \n",
      "맥락을 파악하는 것과 비슷하다. 예를 들어, “배가 바다를 항해한다”와 “배가 고프다”라는 두 문장에서 ‘배’라는 \n",
      "단어의 의미가 다르다는 것을 문맥을 통해 이해하는 것과 같다. 트랜스포머는 이러한 방식으로 단어들 사이의 \n",
      "관계를 파악하고, 문장의 의미를 정확하게 이해한다. 또한, 여러 문장을 동시에 처리할 수 있어 매우 빠르게 \n",
      "작동한다.\n",
      "③ 예시와 함께 좀 더 자세히 알아볼까?\n",
      "트랜스포머의 핵심은 ‘어텐션 메커니즘(Attention Mechanism)’이라는 기술이다. 이는 마치 사람이 문장을 \n",
      "읽을 때 중요한 부분에 집중하는 것과 같다. 예를 들어, “나는 파란 하늘을 보며 행복을 느꼈다”라는 문장에서\n",
      "\n",
      "==== 청킹 결과 (1번) ====:\n",
      "관계를 파악하고, 문장의 의미를 정확하게 이해한다. 또한, 여러 문장을 동시에 처리할 수 있어 매우 빠르게 \n",
      "작동한다.\n",
      "③ 예시와 함께 좀 더 자세히 알아볼까?\n",
      "트랜스포머의 핵심은 ‘어텐션 메커니즘(Attention Mechanism)’이라는 기술이다. 이는 마치 사람이 문장을 \n",
      "읽을 때 중요한 부분에 집중하는 것과 같다. 예를 들어, “나는 파란 하늘을 보며 행복을 느꼈다”라는 문장에서 \n",
      "‘행복’이라는 감정은 ‘파란 하늘’과 연관이 있다. 트랜스포머는 이러한 관계를 파악하여 문장의 의미를 이해\n",
      "한다.\n",
      "\n",
      "==== 청킹 결과 (2번) ====:\n",
      "실생활에서의 예를 들어보자. 당신이 외국어 학습 앱을 사용하고 있다고 가정해보자. 이 앱이 트랜스포머 기\n",
      "술을 사용한다면, “I love eating apples”라는 문장을 번역할 때 단순히 단어 하나하나를 번역하는 것이 아\n",
      "니라, 문장 전체의 맥락을 고려하여 “나는 사과 먹는 것을 좋아한다”라고 자연스럽게 번역할 수 있다. \n",
      "④ 왜 중요한가?\n",
      "트랜스포머의 중요성은 크게 두 가지로 나눌 수 있다. 첫째, 언어 이해와 생성 능력을 크게 향상시켰다. 이는 \n",
      "번역, 요약, 질문 답변 등 다양한 언어 관련 작업의 성능을 획기적으로 개선한다. 둘째, 다양한 형태의 데이터를 \n",
      "함께 처리할 수 있는 기반을 마련한다. 이는 텍스트뿐만 아니라 이미지, 음성 등을 함께 이해하고 생성할 수 \n",
      "있는 멀티모달 AI의 발전을 이끈다.\n",
      "예를 들어, 의료 분야에서 트랜스포머 기반 AI는 환자의 증상 설명(텍스트), X-ray 이미지, 과거 진료 기록 \n",
      "등을 종합적으로 분석하여 더 정확한 진단을 내리는 데 도움을 줄 수 있다. 이처럼 트랜스포머는 AI가 보다 \n",
      "인간적이고 종합적인 판단을 할 수 있게 해주는 중요한 기술이다.\n",
      "⑤ 어디에 활용되는가?\n",
      "트랜스포머는 우리 일상 곳곳에서 활용되고 있다. 가장 대표적인 예는 번역 서비스이다. 구글 번역\n",
      "11)과 같은 \n",
      "번역 앱들은 트랜스포머 기술을 활용하여 더 자연스러운 번역을 제공한다. 또한, 스마트폰의 음성 비서나 챗\n",
      "봇도 트랜스포머 기술을 기반으로 작동한다. 이들은 사용자의 질문을 정확히 이해하고 적절한 답변을 생\n",
      "성한다.\n",
      "더 나아가, 최근에는 달-이(DALL-E)나 미드저니(Midjourney)와 같은 이미지 생성 AI에도 트랜스포머 기술이 \n",
      "활용되고 있다. 이들은 텍스트 설명을 기반으로 이미지를 생성하는데, 예를 들어 “해변에서 서핑하는 강아지”\n",
      "\n",
      "==== 청킹 결과 (3번) ====:\n",
      "봇도 트랜스포머 기술을 기반으로 작동한다. 이들은 사용자의 질문을 정확히 이해하고 적절한 답변을 생\n",
      "성한다.\n",
      "더 나아가, 최근에는 달-이(DALL-E)나 미드저니(Midjourney)와 같은 이미지 생성 AI에도 트랜스포머 기술이 \n",
      "활용되고 있다. 이들은 텍스트 설명을 기반으로 이미지를 생성하는데, 예를 들어 “해변에서 서핑하는 강아지”\n",
      "라는 설명만으로도 그에 맞는 이미지를 만들어낼 수 있다.\n",
      "교육 분야에서도 트랜스포머 기술이 활용되고 있다. 개인화된 학습 콘텐츠를 추천하거나, 학생의 답변을 자동\n",
      "으로 채점하고 피드백을 제공하는 등 다양한 방식으로 활용되고 있다.\n",
      "이처럼 트랜스포머는 우리 생활 전반에 걸쳐 AI 기술의 성능을 높이고, 더욱 지능적이고 자연스러운 서비스를 \n",
      "제공하는 데 기여하고 있다.\n",
      "11) Google Translate Architecture illustrated (VivienLa, 2024)\n",
      "\n",
      "==== 청킹 결과 (4번) ====:\n",
      "2.2. BERT (Bidirectional Encoder Representations from Transformers): 맥락을 이해하는 언어 \n",
      "모델, 멀티모달 AI의 기반을 다지다\n",
      "① 왜 나오게 되었는가?\n",
      "BERT는 언어의 복잡성과 맥락을 더 잘 이해하기 위해 개발되었다. 기존의 자연어 처리 모델은 마치 외국어를 \n",
      "단어장으로만 공부하는 학생처럼, 단어의 순서나 개별적인 의미에만 집중했다. 하지만 실제 언어는 훨씬 복잡\n",
      "하다. 예를 들어, “배”라는 단어는 문맥에 따라 ‘과일’일 수도 있고, ‘운송 수단’일 수도 있으며, ‘신체 부위’를 \n",
      "가리킬 수도 있다. 이렇게 문맥에 따라 달라지는 단어의 의미를 정확히 파악하기 위해 BERT가 등장했다. \n",
      "BERT는 ‘Bidirectional Encoder Representations from Transformers’의 약자로, ‘양방향 인코더 표현을 \n",
      "위한 트랜스포머’라고 해석할 수 있다.\n",
      "② 쉽게 설명하면?\n",
      "BERT는 마치 뛰어난 독해 능력을 가진 학생처럼 문장 전체의 맥락을 고려하여 각 단어의 의미를 이해한다. 이 \n",
      "모델은 문장을 앞에서부터 읽는 것뿐만 아니라, 뒤에서부터도 읽어 전후 맥락을 모두 파악한다. 이는 마치 추리 \n",
      "소설을 읽을 때 앞뒤 문맥을 모두 고려하여 범인을 추리하는 것과 비슷하다. BERT는 이러한 방식으로 대량의 \n",
      "텍스트 데이터를 학습하여, 다양한 언어 관련 작업에서 뛰어난 성능을 보인다.\n",
      "③ 예시와 함께 좀 더 자세히 알아볼까?\n",
      "BERT의 작동 방식을 일상적인 예로 설명해보자. 당신이 친구에게 “나 어제 배 먹었어”라는 문자를 받았다고 \n",
      "가정해보자. 여기서 ‘배’가 과일인지, 아니면 배를 타고 어딘가를 다녀왔다는 의미인지는 문맥을 알아야 파악\n",
      "할 수 있다. BERT는 이전 대화 내용, 계절, 친구의 평소 습관 등을 모두 고려하여 ‘배’의 의미를 정확히 파악\n",
      "할 수 있다.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 Indexing - Embedding 실습"
   ],
   "metadata": {
    "id": "b0aDzfvvflKJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")"
   ],
   "metadata": {
    "id": "eIWqxVlO3D5Q"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_embed_vector = embeddings.embed_query(split_text_list[0][0].page_content)\n",
    "print(len(sample_embed_vector))\n",
    "print(sample_embed_vector)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LY74cfSo5NM-",
    "outputId": "2f3c4302-d8c3-4a41-feee-8c09ebc2bffa"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1024\n",
      "[0.03007318824529648, -3.664111500256695e-05, 0.010532170534133911, -0.014660526998341084, 0.03664563223719597, -0.022226205095648766, -0.055312998592853546, 0.06849735230207443, 0.03371273726224899, -0.002091482514515519, 0.024185681715607643, 0.000638130703009665, -0.01992986351251602, 0.011674349196255207, -0.03622124344110489, -0.011269647628068924, -0.07575508207082748, 0.0067330473102629185, -0.024584880098700523, -0.025378774851560593, 0.03971973434090614, 0.003252933965995908, -0.03932134807109833, -0.018640289083123207, -0.006245885975658894, 0.0158940851688385, -0.021302586421370506, -0.03157446160912514, -0.009396188892424107, -0.01748298481106758, -0.009663679637014866, 0.01044426392763853, -0.03344186767935753, -0.05943981185555458, -0.0054292092099785805, 0.02830890379846096, 0.025016700848937035, 0.03441617265343666, -0.05709310993552208, 0.056345414370298386, 0.0058083017356693745, 0.05331774801015854, 0.008165845647454262, -0.024034636095166206, -0.011997032910585403, 0.015702491626143456, 0.03010852448642254, -0.010977122001349926, -0.01676148548722267, 0.029625840485095978, 0.010122221894562244, -0.014859933406114578, -0.024496767669916153, -0.01588575169444084, -0.06832512468099594, 0.007064197678118944, -0.06767003238201141, 0.01330934651196003, -0.025103863328695297, 0.023702869191765785, -0.024648983031511307, 0.06633558124303818, 0.06789697706699371, -0.027373334392905235, -0.025605354458093643, 0.012708804570138454, 0.02891169674694538, 0.02862073853611946, -0.021917935460805893, 0.004369465634226799, 0.005443650763481855, 0.03090016357600689, -0.015059666708111763, -0.01284523494541645, -0.038855377584695816, 0.012714930810034275, 0.013391687534749508, -0.035774972289800644, 0.01730719394981861, 0.0008836697088554502, 0.058880873024463654, -0.0004938687779940665, 0.011778309009969234, -0.01661594957113266, 0.0289408341050148, 0.022709611803293228, 0.03317265585064888, 0.030154036357998848, 0.013846935704350471, 0.05175832286477089, 0.021503152325749397, 0.04940428212285042, 0.044990476220846176, -0.00029829860432073474, -0.03377445042133331, -0.047937631607055664, 0.03260479122400284, 0.0381167009472847, -0.0550888329744339, -0.015508709475398064, -0.05206799507141113, 0.002690043533220887, -0.012089267373085022, -0.007402899209409952, -0.030168544501066208, 0.026774581521749496, 0.0304439514875412, 0.018155112862586975, -0.019350843504071236, -0.011580350808799267, 0.012122908607125282, 0.04903179407119751, 0.01341969147324562, -0.0024082649033516645, -0.05037515610456467, 0.004287190735340118, 0.02724146470427513, -0.016657385975122452, -0.03517865017056465, 0.04319563880562782, 0.023036831989884377, -0.009422593750059605, 0.035516176372766495, -0.05998607352375984, 0.04099792242050171, -0.016235342249274254, 0.0123896524310112, 0.03453925997018814, -0.023639362305402756, 0.017470015212893486, -0.004454401787370443, 0.024170367047190666, -0.04692528396844864, -0.008544322103261948, -0.061358388513326645, -0.03761815279722214, 0.009231648407876492, -0.0177358016371727, 0.001794045208953321, -0.005125006195157766, -0.005083168391138315, 0.01923959329724312, 0.03348730877041817, -0.01573927514255047, -0.0418504923582077, -0.0709371566772461, -0.022961437702178955, 0.012806936167180538, -0.020258160308003426, 0.005491671618074179, -0.010275092907249928, -0.008190023712813854, -0.01738058775663376, 0.03633342310786247, 0.00882057473063469, -0.026410503312945366, 0.004418054595589638, 0.04332656040787697, 0.009467056952416897, 0.02803054451942444, -0.04148835316300392, -0.02814210206270218, -0.043451402336359024, -0.02219337970018387, 0.015922587364912033, -0.004618947859853506, 0.002841351320967078, 0.006614259909838438, 0.013590838760137558, -0.028857579454779625, -0.0018110624514520168, -0.016504483297467232, 0.00956036988645792, -0.017988434061408043, -0.017717162147164345, 0.024923859164118767, 0.042514171451330185, 0.06984356790781021, 0.011141917668282986, 0.007518073543906212, 0.03229787200689316, 0.04325167462229729, 0.034059565514326096, -0.005142635200172663, -0.01329807285219431, 0.021890027448534966, 0.01794467493891716, 0.00540367653593421, 0.016544997692108154, 0.03183070942759514, 0.008350599557161331, 0.0064458404667675495, 0.010302205570042133, 0.0773933008313179, -0.010855469852685928, 0.04344237223267555, 0.025408469140529633, 0.02040622942149639, -0.02283352054655552, -0.0029022067319601774, 0.003911906853318214, 0.026429612189531326, -0.0388345941901207, -0.002423031022772193, 0.029057879000902176, -0.04429471492767334, -0.0654645711183548, -0.06952793151140213, 0.025972116738557816, -0.006433356087654829, -0.08812761306762695, -0.01429720874875784, 0.05325400084257126, -0.025921115651726723, -0.02771088480949402, -0.070450559258461, -0.044891107827425, -0.01268783025443554, 0.0064809368923306465, 0.007747357245534658, 0.024678386747837067, 0.03341164067387581, -0.014798891730606556, 0.0415896475315094, 0.018591785803437233, -0.004895428661257029, 0.022190993651747704, 0.0495963953435421, 0.014075337909162045, 0.05020778626203537, 0.01811348833143711, -0.000514971383381635, -0.03760116174817085, -0.03830784186720848, -0.012715321965515614, -0.01674026995897293, -0.03255163133144379, 0.01658804714679718, 0.0316196084022522, 0.05233835428953171, -0.014875376597046852, 0.004074361175298691, -0.012345770373940468, -0.01720653846859932, -0.07414809614419937, 0.010154982097446918, -0.014406034722924232, -0.011218122206628323, -0.007167090196162462, -0.008672150783240795, 0.018017813563346863, 0.03880349174141884, -0.02741086855530739, -0.00967608392238617, 0.04041915759444237, 0.01948278397321701, 0.020409945398569107, 0.007362669799476862, -0.023058032616972923, -0.026369549334049225, 0.024068200960755348, 0.014031666330993176, -0.0013789193471893668, 0.058360226452350616, 0.027660038322210312, 0.024790756404399872, -0.019599754363298416, -0.04694337397813797, -0.0025357918348163366, -0.05514371022582054, -0.014602217823266983, -0.04023551195859909, -0.034622058272361755, -0.020759107545018196, -0.036310046911239624, 0.03441803529858589, -0.0557887889444828, -0.024807486683130264, 0.017741741612553596, 0.021808713674545288, 0.018470514565706253, -0.04510397091507912, 0.030656861141324043, -0.04029887542128563, 0.0059988051652908325, -0.001550395623780787, 0.028055012226104736, -0.016866980120539665, -0.003945323172956705, -0.029066026210784912, 0.025067338719964027, -0.01701093278825283, 0.10193053632974625, 0.0030416271183639765, 0.020047500729560852, -0.017776792868971825, -0.03734901174902916, 0.010302533395588398, -0.03668294474482536, 0.007434431463479996, -0.00011486103176139295, 0.001451762393116951, 0.022633228451013565, 0.031307704746723175, -0.043920356780290604, -0.010506672784686089, -0.014494964852929115, 0.011565281078219414, -0.040500786155462265, 0.019749656319618225, -0.006793992593884468, 0.03045441024005413, 0.006397775374352932, -0.019481273368000984, 0.0032507104333490133, -0.026215314865112305, -0.029468100517988205, 0.056999970227479935, -0.05392919108271599, 0.04180688038468361, -0.05803069844841957, -0.02274521067738533, -0.042605265974998474, 0.037990618497133255, 0.06085082143545151, 0.01070498302578926, 0.024716001003980637, -0.015938377007842064, 0.030217846855521202, 0.004875654820352793, 0.04154383763670921, -0.016970669850707054, -0.010817361064255238, 0.026556437835097313, -0.024625485762953758, 0.014843681827187538, -0.028632719069719315, 0.0057112956419587135, 0.012340054847300053, 0.006929592229425907, 0.04956841841340065, -0.025522589683532715, -0.009858505800366402, -0.0038160360418260098, 0.04132026433944702, -0.04919154942035675, 0.031544800847768784, -0.015379214659333229, 0.035566557198762894, 0.03312623128294945, 0.024587294086813927, -0.00400640768930316, 0.0036862511187791824, 0.004257659427821636, 0.004880810156464577, 0.026936741545796394, -0.00038631269126199186, -0.045123402029275894, 0.07669326663017273, -0.02555163949728012, 0.0194220170378685, -0.008331697434186935, 0.029757414013147354, 0.003651023842394352, 0.015635794028639793, -0.009309015236794949, -0.013887706212699413, 6.744696293026209e-05, -0.019587498158216476, -0.036409541964530945, 0.03097868338227272, 0.06603211164474487, -0.03494267910718918, 0.025707993656396866, 0.0004873881407547742, -0.026076264679431915, -0.03942351043224335, -0.009915821254253387, 0.05457025021314621, -0.015030945651233196, -0.017887072637677193, -0.029093805700540543, 0.004178487230092287, -0.025300320237874985, -0.056338973343372345, -0.047438785433769226, 0.1444236934185028, 0.008080408908426762, 0.01253630593419075, -0.04735670983791351, -0.013275464996695518, 0.025419622659683228, 0.03383628651499748, 0.01477693859487772, 0.025145387277007103, 0.017440514639019966, -2.400646553724073e-05, 0.02509315311908722, 0.04600811004638672, -0.022154418751597404, 0.00885364506393671, 0.046058289706707, 0.021021105349063873, 0.026677420362830162, 0.03650708869099617, -0.01710408180952072, 0.03374846652150154, -0.04683087021112442, -0.020146451890468597, 0.03299957141280174, -0.06966765224933624, -0.03141798824071884, -0.004187912680208683, 0.017828812822699547, -0.03545878082513809, 0.008849072270095348, -0.00974908098578453, 0.016219614073634148, -0.030531883239746094, -0.014974678866565228, 0.032269708812236786, 0.046665240079164505, -0.0027630270924419165, -0.033264465630054474, 0.05681499093770981, -0.016391240060329437, -0.04192150756716728, -0.03720638528466225, -0.0024406020529568195, 0.04926316440105438, -0.013377533294260502, 0.03800618276000023, 0.03522327542304993, -0.0005409790901467204, -0.035053834319114685, -0.012753907591104507, 0.04184333235025406, 0.004426824394613504, -0.004733086097985506, -0.03833683207631111, 0.015761280432343483, -0.04607972130179405, -0.01520652137696743, 0.012894201092422009, 0.001986817689612508, 0.031980961561203, 0.0972394272685051, 0.026751579716801643, -0.04327846318483353, -0.04545384645462036, 0.03548131138086319, 0.02847743220627308, -0.014506652019917965, -0.06627041846513748, -0.07876672595739365, -0.012405285611748695, -0.044646475464105606, -0.016750311478972435, -0.033539146184921265, 0.011106970719993114, -0.02715737745165825, -0.02907893806695938, 0.018879085779190063, 0.05385066196322441, 0.013326548039913177, -0.012573269195854664, 0.024232840165495872, -0.0363631434738636, -0.029255837202072144, 6.1005805036984384e-05, 0.04851866513490677, -0.009977474808692932, 0.017511285841464996, 0.023679068312048912, -0.03095930814743042, 0.030199604108929634, 0.027071136981248856, -0.02464679814875126, 0.008049960248172283, 0.04020637646317482, 0.03641718998551369, -0.0445127934217453, 0.016707956790924072, 0.013844550587236881, -0.0025072211865335703, 0.013368349522352219, -0.012690572068095207, 0.014064841903746128, 0.00413179025053978, 0.02518486976623535, 0.01372698787599802, -0.03417893126606941, 0.060984332114458084, 0.04178191348910332, 0.005638648755848408, 0.025545528158545494, 0.03696681186556816, -0.012361646629869938, 0.007369669619947672, -0.032632019370794296, -0.005823477637022734, 0.018309537321329117, 0.019207190722227097, -0.02960081212222576, 0.00593345332890749, 0.01461122278124094, -0.020216558128595352, 0.012370714917778969, -0.029993077740073204, 0.05547219514846802, -0.036377038806676865, 0.03849714621901512, -0.0023168784100562334, 0.02964792773127556, 0.03124072402715683, 0.007865607738494873, 0.0007476204773411155, -0.009839474223554134, 0.011959250085055828, 0.030070872977375984, 0.01658555679023266, -0.02653123065829277, 0.021580159664154053, 0.008571199141442776, -0.02386392652988434, 0.017518801614642143, -0.01914457604289055, 0.04115485027432442, -0.05780930072069168, 0.016492964699864388, 0.03312787041068077, 0.02697673998773098, -0.056124258786439896, -0.04997669532895088, -0.013689934276044369, -0.02537340112030506, 0.03252524137496948, -0.025974567979574203, -0.02572290226817131, 0.035814329981803894, -0.005721893161535263, -0.05454161763191223, 0.02638022042810917, 0.016602374613285065, 0.015537538565695286, -0.02807461842894554, -0.042161647230386734, 0.013999502174556255, -0.014094492420554161, 0.08719837665557861, 0.04757864773273468, 0.04911884665489197, -0.024369977414608, 0.025543024763464928, 0.029254622757434845, 0.0003722943947650492, -0.056333716958761215, -0.019138680770993233, 0.020366832613945007, 0.017815347760915756, 0.03237832710146904, -0.028188085183501244, -0.02446422539651394, 0.023530058562755585, -0.025028668344020844, 0.0068021309562027454, -0.0009802639251574874, 0.061651136726140976, 0.02703206054866314, 0.015474275685846806, -0.04619205743074417, 0.035727936774492264, 0.0005539191770367324, -0.01600814238190651, -0.04024957865476608, -0.009981615468859673, -0.02169969119131565, 0.1320849508047104, -0.006991456262767315, 0.035271983593702316, -0.01131112314760685, 0.03235187008976936, -0.03560178354382515, -0.0004095778276678175, -0.030166884884238243, -0.036901723593473434, -0.013194329105317593, -0.04063475504517555, -0.023721447214484215, 0.0006874835817143321, -0.022461971268057823, -0.034200143069028854, -0.016148554161190987, -0.006879897788167, 0.014281184412539005, 0.020945502445101738, -0.032347872853279114, -0.018878953531384468, 0.04233196750283241, 0.005125638097524643, 0.027690909802913666, 0.015475471504032612, 0.005540257319808006, 0.03801873326301575, 0.011580544523894787, -0.032224398106336594, 0.022132091224193573, 0.00880446471273899, 0.04626525565981865, -0.011272625997662544, -0.013727429322898388, -0.005293445196002722, 0.027115534991025925, 0.040032029151916504, 0.012424467131495476, -0.012194830924272537, -0.0005050623440183699, 0.003813703777268529, -0.031134366989135742, -0.049669694155454636, -0.009421671740710735, 0.005382423289120197, 0.026063470169901848, 0.04003411903977394, 0.021487945690751076, -0.031114259734749794, 0.04231667146086693, -0.017516929656267166, 0.06121916323900223, 0.005744054447859526, -0.017775192856788635, -0.019908497110009193, -0.005993388593196869, 0.01812788099050522, 0.06230730563402176, 0.01642562635242939, 0.010236497968435287, -0.037125758826732635, 0.015407866798341274, 0.05303175374865532, -0.01602947525680065, -0.020684432238340378, 0.02785498835146427, -0.02140800468623638, -0.015724817290902138, -0.039224766194820404, 0.010872277431190014, -0.01598336175084114, -0.020401928573846817, -0.01596173457801342, -0.026090262457728386, 0.03080975078046322, 0.04186346381902695, -0.009826604276895523, -0.040063463151454926, -0.03911899775266647, 0.016881203278899193, -0.036965806037187576, -0.05236861854791641, -0.05549819394946098, 0.08778908103704453, 0.006444627419114113, -0.014869889244437218, -0.05112089961767197, -0.026187358424067497, 0.004875179845839739, -0.07164005190134048, 0.09213049709796906, 0.052842892706394196, -0.020200110971927643, 0.02120419591665268, 0.030311891809105873, -0.017024585977196693, -0.005602206569164991, 0.0012590221595019102, -0.061918340623378754, -0.029438061639666557, 0.02794523537158966, 0.0014222693862393498, 0.016434457153081894, -0.004539279732853174, -0.054723650217056274, -0.02970309555530548, -0.03166668862104416, -0.033310920000076294, -0.043810587376356125, 0.024458665400743484, -0.023413030430674553, -0.05251293256878853, -0.01933584362268448, -0.015056179836392403, 0.01868814416229725, -0.04999852180480957, 0.00031903188209980726, 0.04260571300983429, 0.04592903330922127, -0.02363547496497631, 0.0015626288950443268, 0.018717657774686813, 0.050073884427547455, -0.019959593191742897, 0.015936918556690216, 0.025941649451851845, -0.008276526816189289, -0.01404541451483965, 0.01905166544020176, 0.007878890261054039, -0.009769439697265625, -0.02850743941962719, -0.017315350472927094, 0.04016154631972313, 0.017598934471607208, 0.040612585842609406, 0.019052062183618546, 0.009971768595278263, -0.03415866196155548, 0.00510428985580802, -0.013815775513648987, -0.07251040637493134, -0.032822709530591965, -0.0281567070633173, -0.04144524410367012, -0.014170458540320396, -0.025287555530667305, -0.004986944142729044, -0.05835559964179993, -0.002029125578701496, 0.03961094468832016, 0.0194779671728611, -0.026100683957338333, 0.04512175917625427, 0.01381516270339489, -0.006684981286525726, 0.03381621837615967, -0.024326948449015617, -0.01811080612242222, -0.011603069491684437, 0.05090709030628204, -0.03397620469331741, -0.021643033251166344, -0.03880646824836731, 0.035615552216768265, -0.04782460257411003, 0.04069129005074501, -0.0004599624371621758, -0.009452681988477707, -0.004027482587844133, -0.025920739397406578, 0.019782686606049538, -0.04178762063384056, -0.05003662034869194, -0.005941410548985004, -0.041026659309864044, 0.035732295364141464, 0.014490729197859764, 0.014329486526548862, -0.020119881257414818, -0.012243043631315231, -0.05894896760582924, -0.03361521661281586, -0.028915630653500557, 0.004695000592619181, -0.027925346046686172, 0.014566062018275261, 0.013733754865825176, -0.004425367806106806, 0.020624371245503426, -0.03592202439904213, -0.007681303657591343, -0.027158569544553757, 0.027902625501155853, -0.04389875754714012, -0.009303520433604717, 0.023832162842154503, 0.022873030975461006, 0.029980167746543884, -0.043421581387519836, 0.04043660685420036, -0.008838350884616375, -0.02368115447461605, -0.07059871405363083, -0.012882478535175323, 0.008828066289424896, -0.012834059074521065, -0.034588851034641266, -0.03694577142596245, -0.01482551358640194, 0.018241913989186287, 0.0031061272602528334, -0.011874976567924023, -0.008167464286088943, 0.002033993136137724, 0.01332327350974083, -0.038687556982040405, -0.021968280896544456, 0.03532535210251808, 0.03476030379533768, -0.014695127494633198, 0.017289306968450546, -0.0033642761409282684, 0.004148364067077637, -0.003627604339271784, -0.0014541494892910123, -0.010459169745445251, 0.03324716538190842, 0.009784966707229614, 0.03624929115176201, 0.01954389549791813, -0.070365309715271, -0.04633652791380882, -0.0022345774341374636, 0.002000611973926425, 0.026173759251832962, 0.04094014689326286, -0.03899175301194191, 0.018647575750947, 0.008988510817289352, -0.02516193315386772, -0.037100665271282196, -0.003072066931053996, -0.007817649282515049, -0.004667407367378473, -0.011098098941147327, -0.01708739623427391, -0.039386242628097534, 0.02307097800076008, 0.02774782106280327, -0.07314472645521164, 0.023229241371154785, -0.04117678850889206, -0.0029489181470125914, 0.006184101570397615, 0.009521827101707458, 0.008552255108952522, 0.002453835681080818, 0.02394263446331024, 0.017757050693035126, -0.028649505227804184, -0.01147855818271637, 0.055237747728824615, 0.03867066279053688, -0.03016745299100876, -0.020720483735203743, -0.014948306605219841, -0.03219623863697052, -0.010224073193967342, -0.048110540956258774, 0.025002529844641685, -0.04744108393788338, 0.04190915450453758, -0.010465296916663647, -0.024094197899103165, 0.027034208178520203, -0.009785126894712448, 0.0510399229824543, -0.04170181229710579, -0.016318047419190407, 0.018128065392374992, 0.02157987281680107, 0.01175969559699297, -0.041675444692373276, -0.016525739803910255, -0.004669210407882929, -0.032611556351184845, -0.03402772918343544, -0.0148239154368639, 0.020273882895708084, -0.009182197973132133, -0.035111479461193085, 0.008500760421156883, -0.029005438089370728, 0.007956495508551598, 0.003959407564252615, -0.01632555201649666, -0.009430871345102787, -0.04303393140435219, -0.04036213457584381, 0.0196632519364357, 0.02903597801923752, 0.01408512145280838, -0.018506541848182678, 0.00606467155739665, 0.017680760473012924, 0.009056580252945423, 0.012247649021446705, -0.030353091657161713, 0.015095267444849014, -0.016231125220656395, 0.04446407034993172, -0.03370143473148346, -0.035092439502477646, 0.004491303116083145, -0.040714044123888016, -0.014728333801031113, -0.04851507395505905, 0.020350266247987747, -0.00442071259021759, 0.0011416724883019924, -0.028250517323613167, 0.05089785158634186, -0.014978135004639626, -0.048716433346271515, 0.05912353843450546, -0.04285334423184395, 0.005035067442804575, 0.033769749104976654, 0.004768902435898781, -0.05070912092924118, 0.03947598487138748, -0.06247682124376297, 0.04320565238595009, -0.02271135151386261, 0.0026848320849239826, -0.010915400460362434, -0.03691678121685982, -0.004793399479240179, -0.03322667255997658, 0.12323138862848282, -0.02356305904686451, 0.0426371768116951, -0.023450888693332672, -0.033285144716501236, -0.0274007860571146, -0.009115549735724926, -0.01806914433836937, 0.029444919899106026, -0.04460390284657478, -0.04880614951252937, -0.027118777856230736, -0.03845773637294769, 0.031464461237192154, 0.021008573472499847, -0.012573108077049255, 0.04481768608093262, -0.00476829381659627, 0.02602127380669117, 0.028320439159870148, -0.022066203877329826, 0.015484048053622246, 0.03275524452328682, -0.020651033148169518, 0.03843315318226814, -0.0052392748184502125, 0.04116775840520859, 0.01930648647248745, -0.041498422622680664, 0.013719303533434868, 0.021098213270306587, 0.019396133720874786, -0.01680159568786621, 0.030847027897834778, 0.019349785521626472, -0.059137653559446335, 0.018480980768799782, 0.035493217408657074, -0.004612120334059, 0.05565651133656502, 0.05060422420501709, 0.027709761634469032, 0.026725659146904945, -0.008504096418619156, -0.01953970640897751, -0.015721770003437996, 0.02307484671473503, 0.015637001022696495, 0.00517036160454154, 0.07043758034706116, 0.02655738778412342, 0.012406052090227604, 0.02438240684568882, 0.004577373154461384, 0.013834278099238873, 0.009952985681593418, 0.05771329253911972, 0.025304799899458885, -0.03980482369661331, -0.007341544143855572, 0.023702632635831833, -0.0355273112654686, -0.0018385492730885744, 0.0020444216206669807, -0.022663353011012077, 0.013908717781305313, -0.0391138531267643, -0.010552067309617996, 0.02612031064927578, -0.054036419838666916, 0.031815942376852036, -0.02754190005362034, 0.0362529456615448, 0.038753531873226166, -0.0491943396627903, 0.005345448385924101, 0.03313252329826355, 0.024018874391913414, 0.01834792271256447, 0.040802400559186935, -0.01861700601875782, 0.02285054139792919, 0.00154660374391824, 0.014444679021835327, 0.03124346397817135, -0.032590094953775406, -0.004369123373180628, -0.04310782626271248, -0.02059103734791279, -0.02465038187801838, 0.031632199883461, -0.016972262412309647, -0.01720338873565197, 0.004553921055048704, 0.03182666748762131, 0.03083346225321293, 0.002915777964517474, -0.004673963412642479, -0.021096674725413322, 0.01566637121140957, 0.005954517051577568, 0.01263635978102684, 0.013003296218812466, 0.034771256148815155, -0.019108852371573448, -0.02530275098979473, 0.011821187101304531]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.4 Indexing - Save VectorDB 실습\n",
    "\n",
    "\n",
    "본격적인 시작에 앞서 vector database 패키지를 다운로드 해줍니다"
   ],
   "metadata": {
    "id": "Z3fBbOo_hSS5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Hxqpp6JLax-F",
    "outputId": "e7ed0502-1ab2-453d-bbd4-7c1f3a56a8ba"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (0.3.44)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (1.26.4)\n",
      "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 (from langchain-chroma)\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.10.6)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading posthog-3.20.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.31.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.31.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.3/67.3 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.71.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.15.2)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (0.3.13)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.25.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.69.1)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.52b0)\n",
      "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.2)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Downloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m611.1/611.1 kB\u001B[0m \u001B[31m40.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m87.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m284.2/284.2 kB\u001B[0m \u001B[31m26.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.9/94.9 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m81.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.6/101.6 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.0/16.0 MB\u001B[0m \u001B[31m84.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.9/55.9 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl (7.3 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.20.0-py2.py3-none-any.whl (79 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.3/79.3 kB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.3/62.3 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m459.8/459.8 kB\u001B[0m \u001B[31m32.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m319.7/319.7 kB\u001B[0m \u001B[31m24.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.0/72.0 kB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m78.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m452.6/452.6 kB\u001B[0m \u001B[31m33.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=4829df6201b13f6c44bfb6b90a0edad9a54d969a37bb4ed6b1ef65c316c6a1f4\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.6\n",
      "    Uninstalling protobuf-4.25.6:\n",
      "      Successfully uninstalled protobuf-4.25.6\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.11 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 langchain-chroma-0.2.2 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-grpc-1.31.0 opentelemetry-instrumentation-0.52b0 opentelemetry-instrumentation-asgi-0.52b0 opentelemetry-instrumentation-fastapi-0.52b0 opentelemetry-proto-1.31.0 opentelemetry-util-http-0.52b0 overrides-7.7.0 posthog-3.20.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.46.1 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "COLLECTION_NAME=\"test\"\n",
    "\n",
    "# 저장소 생성\n",
    "store = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# 재실행을 대비하여 저장소 초기화\n",
    "store.reset_collection()\n",
    "\n",
    "# 모든 document 들을 저장소에 추가하기\n",
    "for split_text in split_text_list:\n",
    "    before_count = store._collection.count()\n",
    "    store.add_documents(split_text)\n",
    "    after_count = store._collection.count()\n",
    "    print(f\"저장소에 document 추가: 총합({before_count} -> {after_count})\")\n"
   ],
   "metadata": {
    "id": "8ePeDrlEbbLd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "77944d1e-1fdd-402c-8247-8b78f081b33d"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "저장소에 document 추가: 총합(0 -> 10)\n",
      "저장소에 document 추가: 총합(10 -> 23)\n",
      "저장소에 document 추가: 총합(23 -> 34)\n",
      "저장소에 document 추가: 총합(34 -> 45)\n",
      "저장소에 document 추가: 총합(45 -> 52)\n",
      "저장소에 document 추가: 총합(52 -> 59)\n",
      "저장소에 document 추가: 총합(59 -> 69)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Retrieve - 검색 실습\n"
   ],
   "metadata": {
    "id": "tyGH1-Fj9fXw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results = store.similarity_search(\"Embodied 에 대한 정보를 자료를 기반으로 설명해줘\", k=4)\n",
    "\n",
    "for doc in results:\n",
    "  print(doc.page_content)\n",
    "  print()\n",
    "  print(\"=\"*100)\n",
    "  print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rf_i1YnV9yob",
    "outputId": "cb06ec2a-a68a-43d2-f08d-277823123396"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "이처럼 Embodied AI는 실제 환경에서 경험을 쌓으며 더욱 똑똑해지고 유연해진다.\n",
      "④ 왜 중요한가?\n",
      "Embodied AI의 중요성은 AI가 현실 세계에 더 가까워진다는 점에 있다. 이는 마치 책으로만 공부하던 학생이 \n",
      "실제 현장에서 경험을 쌓는 것과 같다. 이를 통해 AI는 더 실용적이고 유연한 능력을 갖출 수 있다.\n",
      "예를 들어, 재난 현장에서 활동하는 구조 로봇을 생각해보자. 이 로봇은 실제 재난 현장의 불규칙한 지형, 예측 \n",
      "불가능한 상황 등을 직접 경험하며 학습한다. 이런 경험을 통해 로봇은 더 효과적으로 인명을 구조하고 위험을 \n",
      "감지할 수 있게 된다.\n",
      "또한 Embodied AI는 인간과 AI의 상호작용을 더욱 자연스럽게 만든다. 예를 들어, 노인 돌봄 로봇은 실제 \n",
      "노인들과 대화하고 교감하면서 더 섬세하고 인간적인 돌봄 서비스를 제공할 수 있게 된다.\n",
      "⑤ 어디에 활용되는가?\n",
      "Embodied AI는 우리 생활 곳곳에서 활용될 수 있다:\n",
      "Ÿ 가정: 로봇 청소기뿐만 아니라 요리, 빨래, 설거지 등을 돕는 가사 도우미 로봇으로 활용된다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "예를 들어, 로봇 청소기를 생각해보자. 로봇 청소기는 센서로 주변 장애물을 감지하고, 내장된 AI로 청소 경\n",
      "로를 계획하며, 바퀴와 브러시를 움직여 실제로 청소를 수행한다. 이처럼 Embodied AI는 실제 세상에서 직접 \n",
      "경험하고 학습하며 작업을 수행한다.\n",
      "③ 예시와 함께 좀 더 자세히 알아볼까?\n",
      "Embodied AI의 예시는 우리 주변에서 쉽게 찾아볼 수 있다.\n",
      "Ÿ 로봇 강아지: 소니의 ‘아이보’라는 로봇 강아지가 있다. 아이보는 카메라로 주인을 인식하고, 마이크로 음성 \n",
      "명령을 듣는다. AI로 상황을 판단하여 꼬리를 흔들거나 짖는 등의 반응을 보인다. 실제 강아지처럼 주변 \n",
      "환경과 상호작용하며 학습하고 성장한다.\n",
      "Ÿ 자율주행차: 테슬라의 자율주행차는 여러 개의 카메라, 레이더, 초음파 센서 등으로 주변 상황을 파악한다. \n",
      "AI가 이 정보를 분석하여 차량의 속도와 방향을 조절한다. 주행 경험이 쌓일수록 더 안전하고 효율적인 \n",
      "주행이 가능해진다.\n",
      "Ÿ 드론 택배: 아마존이 개발 중인 드론 택배 시스템이 있다. 이 드론은 GPS로 위치를 파악하고, 카메라로 \n",
      "장애물을 인식한다. AI가 최적의 경로를 계산하여 목적지까지 물건을 배달한다. 다양한 환경에서의 비행 \n",
      "경험을 통해 더욱 안정적인 배달이 가능해진다.\n",
      "이처럼 Embodied AI는 실제 환경에서 경험을 쌓으며 더욱 똑똑해지고 유연해진다.\n",
      "④ 왜 중요한가?\n",
      "Embodied AI의 중요성은 AI가 현실 세계에 더 가까워진다는 점에 있다. 이는 마치 책으로만 공부하던 학생이 \n",
      "실제 현장에서 경험을 쌓는 것과 같다. 이를 통해 AI는 더 실용적이고 유연한 능력을 갖출 수 있다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "기존의 AI는 주로 컴퓨터 안에서만 존재하며 데이터를 분석하고 결과를 내놓았다. 이는 마치 책만 보고 세상을 \n",
      "배우는 것과 같다. 하지만 실제 세상은 책에 나오는 것보다 훨씬 복잡하고 예측하기 어렵다.\n",
      "예를 들어, 자율주행차가 도로에서 마주치는 상황은 매번 다르다. 갑자기 뛰어드는 동물, 예기치 못한 공사 \n",
      "현장, 날씨 변화 등 수많은 변수가 있다. 이런 상황에서 AI가 효과적으로 대응하려면 실제 환경과 상호작용하며 \n",
      "학습하고 적응하는 능력이 필요하다. 이런 필요성에 의해 Embodied AI가 탄생했다.\n",
      "② 쉽게 설명하면?\n",
      "Embodied AI는 말 그대로 ‘몸을 가진 AI’이다. 이는 로봇, 드론, 자율주행차 등 물리적인 형태를 가진 AI \n",
      "시스템을 말한다. 이들은 마치 우리 인간처럼 감각 기관(센서)으로 주변을 인식하고, 뇌(AI 알고리듬)로 상황을 \n",
      "판단하며, 근육(모터 등)을 움직여 행동한다.\n",
      "25) 골드만삭스 “10년 뒤 휴머노이드 연간 100만대 이상 생산” (임대준, 골드만삭스 “10년 뒤 휴머노이드 연간 100만대 이상 \n",
      "생산”, 2024)\n",
      "26) ‘AI 끝판왕’ 휴머노이드…인간처럼 ‘촉감’ 가진 로봇 5년내 나온다 (이해성강경주, 2024)\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Ÿ 의료: 정밀한 수술을 돕는 수술 로봇, 환자의 재활을 돕는 재활 로봇 등으로 사용된다.\n",
      "Ÿ 교육: 학생들과 상호작용하며 개별 맞춤 학습을 제공하는 교육용 로봇으로 활용된다.\n",
      "Ÿ 농업: 작물의 상태를 체크하고 자동으로 물을 주거나 농약을 뿌리는 농업용 로봇으로 사용된다.\n",
      "Ÿ 재난 대응: 위험한 재난 현장에 투입되어 인명을 구조하고 상황을 파악하는 구조 로봇으로 활용된다.\n",
      "이처럼 Embodied AI는 단순히 정보를 처리하는 것을 넘어, 실제 세상에서 다양한 작업을 수행하고 인간과 \n",
      "상호작용하는 존재로 발전하고 있다\n",
      "1.2. 휴머노이드AI(Humanoid AI): 인간을 닮은 인공지능, 새로운 가능성을 열다\n",
      "① 왜 나오게 되었는가?\n",
      "휴머노이드 AI는 인공지능을 더 친숙하고 접근하기 쉽게 만들기 위해 탄생했다. 기존의 AI는 주로 컴퓨터 화\n",
      "면이나 스마트폰 속에 갇혀 있었다. 이는 마치 우리가 외국인 친구와 오직 전화로만 대화하는 것과 비슷하다. \n",
      "하지만 인간의 모습을 한 AI, 즉 휴머노이드 AI는 우리와 직접 마주보고 대화하고 상호작용할 수 있다.\n",
      "예를 들어, 노인 돌봄 서비스에서 휴머노이드 AI를 활용한다고 생각해보자. 화면 속 AI보다는 실제 사람처럼 생긴 \n",
      "로봇이 옆에서 대화를 나누고 도움을 주는 것이 노인들에게 훨씬 편안하고 자연스러울 것이다. 이처럼 인간과 \n",
      "더 가깝게 소통하고, 우리 삶에 직접적으로 도움을 줄 수 있는 AI를 만들기 위해 휴머노이드 AI가 등장했다.\n",
      "② 쉽게 설명하면?\n",
      "휴머노이드 AI는 말 그대로 ‘사람을 닮은 AI’이다. 이는 인간의 모습을 한 로봇에 인공지능을 탑재한 시스템을 \n",
      "말한다. 휴머노이드 AI는 우리처럼 두 발로 걸어 다니고, 두 팔을 이용해 물건을 집을 수 있으며, 눈과 귀로 \n",
      "주변 환경을 인식한다. 또한 음성 인식과 자연어 처리 기술을 통해 우리와 대화를 나눌 수 있다.\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tmp_retriever = store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 4,\n",
    "        \"fetch_k\": 10,\n",
    "        \"lambda_mult\": 0.5\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "mmr_results = tmp_retriever.invoke(\"Embodied 에 대한 정보를 자료를 기반으로 설명해줘\")\n",
    "\n",
    "for doc in mmr_results:\n",
    "  print(doc.page_content)\n",
    "  print()\n",
    "  print(\"=\"*100)\n",
    "  print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtCd1CGI9wC5",
    "outputId": "4616321d-0801-489d-887f-5e8e413073b6"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "이처럼 Embodied AI는 실제 환경에서 경험을 쌓으며 더욱 똑똑해지고 유연해진다.\n",
      "④ 왜 중요한가?\n",
      "Embodied AI의 중요성은 AI가 현실 세계에 더 가까워진다는 점에 있다. 이는 마치 책으로만 공부하던 학생이 \n",
      "실제 현장에서 경험을 쌓는 것과 같다. 이를 통해 AI는 더 실용적이고 유연한 능력을 갖출 수 있다.\n",
      "예를 들어, 재난 현장에서 활동하는 구조 로봇을 생각해보자. 이 로봇은 실제 재난 현장의 불규칙한 지형, 예측 \n",
      "불가능한 상황 등을 직접 경험하며 학습한다. 이런 경험을 통해 로봇은 더 효과적으로 인명을 구조하고 위험을 \n",
      "감지할 수 있게 된다.\n",
      "또한 Embodied AI는 인간과 AI의 상호작용을 더욱 자연스럽게 만든다. 예를 들어, 노인 돌봄 로봇은 실제 \n",
      "노인들과 대화하고 교감하면서 더 섬세하고 인간적인 돌봄 서비스를 제공할 수 있게 된다.\n",
      "⑤ 어디에 활용되는가?\n",
      "Embodied AI는 우리 생활 곳곳에서 활용될 수 있다:\n",
      "Ÿ 가정: 로봇 청소기뿐만 아니라 요리, 빨래, 설거지 등을 돕는 가사 도우미 로봇으로 활용된다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "기존의 AI는 주로 컴퓨터 안에서만 존재하며 데이터를 분석하고 결과를 내놓았다. 이는 마치 책만 보고 세상을 \n",
      "배우는 것과 같다. 하지만 실제 세상은 책에 나오는 것보다 훨씬 복잡하고 예측하기 어렵다.\n",
      "예를 들어, 자율주행차가 도로에서 마주치는 상황은 매번 다르다. 갑자기 뛰어드는 동물, 예기치 못한 공사 \n",
      "현장, 날씨 변화 등 수많은 변수가 있다. 이런 상황에서 AI가 효과적으로 대응하려면 실제 환경과 상호작용하며 \n",
      "학습하고 적응하는 능력이 필요하다. 이런 필요성에 의해 Embodied AI가 탄생했다.\n",
      "② 쉽게 설명하면?\n",
      "Embodied AI는 말 그대로 ‘몸을 가진 AI’이다. 이는 로봇, 드론, 자율주행차 등 물리적인 형태를 가진 AI \n",
      "시스템을 말한다. 이들은 마치 우리 인간처럼 감각 기관(센서)으로 주변을 인식하고, 뇌(AI 알고리듬)로 상황을 \n",
      "판단하며, 근육(모터 등)을 움직여 행동한다.\n",
      "25) 골드만삭스 “10년 뒤 휴머노이드 연간 100만대 이상 생산” (임대준, 골드만삭스 “10년 뒤 휴머노이드 연간 100만대 이상 \n",
      "생산”, 2024)\n",
      "26) ‘AI 끝판왕’ 휴머노이드…인간처럼 ‘촉감’ 가진 로봇 5년내 나온다 (이해성강경주, 2024)\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "4. Embodied AI 구현 기술\n",
      "4.1. 주의집중 메커니즘 (Attention Mechanism): AI의 감각과 인지 능력 향상, 세상을 더욱 깊이 \n",
      "이해하다\n",
      "① 왜 나오게 되었는가?\n",
      "주의집중 메커니즘은 AI가 인간처럼 ‘맥락에 맞춰 중요한 정보에 집중’할 수 있도록 만들기 위해 탄생했다. 초기의 \n",
      "AI는 마치 갓 태어난 아기처럼, 주변의 모든 감각 정보를 똑같이 중요하게 여겼다. 예를 들어, Embodied AI 로봇\n",
      "이 방 안을 돌아다닐 때, 벽의 질감, 바닥의 먼지, 창문 밖 풍경 등 모든 정보를 동일하게 처리했다. 하지만 인간은 \n",
      "상황에 따라 중요한 정보에 집중한다. 길을 찾을 때는 주변 지형지물에, 대화할 때는 상대방의 표정과 목소리에 더 \n",
      "주목한다. AI도 이렇게 할 수 있다면 더 효율적으로 세상을 이해하고 상호작용할 수 있을 것이라는 생각에서 주의\n",
      "집중 메커니즘이 개발되었다.\n",
      "② 쉽게 설명하면?\n",
      "주의집중 메커니즘은 AI에게 ‘선택과 집중’의 능력을 부여하는 기술이다. 이는 마치 숲속에서 길을 잃었을 때 나침\n",
      "반을 보며 방향을 찾는 것과 같다. 나침반은 우리에게 북쪽이 어디인지 알려주어 불필요한 방황을 줄여준다. 주의집중 \n",
      "메커니즘은 AI에게 이런 나침반 역할을 한다. 예를 들어, 자율주행 자동차가 복잡한 도로에서 주변 차량, 보행자, \n",
      "신호등 등 중요한 정보에 집중하게 하거나, Embodied AI 로봇이 물체를 잡을 때 물체의 모양, 크기, 위치 등에 \n",
      "집중하게 한다. 이를 통해 AI는 불필요한 정보는 걸러내고 중요한 정보에만 집중하여 더 효율적으로 작업을 수행할 \n",
      "수 있게 된다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "4.3. 멀티모달 퓨전 (Multimodal Fusion): 인공지능의 오감 통합, 더욱 풍부한 세상 이해를 위한 열쇠\n",
      "① 왜 나오게 되었는가?\n",
      "멀티모달 퓨전은 Embodied AI에게 ‘오감’을 주기 위해 탄생했다. 로봇이나 자율주행차와 같은 Embodied \n",
      "AI는 실제 환경에서 작동하며, 다양한 센서를 통해 환경과 상호작용한다. 하지만 초기의 Embodied AI는 마\n",
      "치 한 가지 감각만 가진 존재처럼 제한적으로 정보를 처리했다. 이런 한계를 극복하고 Embodied AI가 인간\n",
      "처럼 다양한 정보를 종합적으로 이해할 수 있도록 멀티모달 퓨전 기술이 개발되었다. 이는 Embodied AI가 \n",
      "복잡하고 역동적인 실제 환경에 더욱 효과적으로 대응할 수 있게 해준다.\n",
      "② 쉽게 설명하면?\n",
      "멀티모달 퓨전은 Embodied AI가 ‘여러 가지 센서 정보를 동시에 고려하여 환경을 이해하는 능력’이라고 할 \n",
      "수 있다. 이는 마치 요리사가 여러 가지 재료를 조화롭게 섞어 맛있는 요리를 만드는 것과 비슷하다. \n",
      "Embodied AI는 카메라(시각), 마이크(청각), 압력 센서(촉각) 등 다양한 센서 데이터를 ‘재료’로 사용하여 더 \n",
      "정확하고 풍부한 ‘요리(환경 이해)’를 만들어낸다. 예를 들어, 자율주행차는 카메라, 라이다, 레이더 등의 정보를 \n",
      "종합하여 주변 환경을 더욱 정확하게 파악할 수 있다.\n",
      "③ 예시와 함께 좀 더 자세히 알아볼까?\n",
      "멀티모달 퓨전의 실제 활용 사례를 살펴보자:\n",
      "Ÿ 서비스 로봇: 서비스 로봇은 멀티모달 퓨전을 활용하여 사용자와 더 자연스럽게 상호작용한다. 예를 들\n",
      "어, 사용자가 “저기 있는 빨간 컵 좀 가져다 주세요”라고 말하면, 로봇은 음성 명령(청각), 사용자의 시선\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.1 Generation - Template 를 활용하여 Prompt 생성 실습"
   ],
   "metadata": {
    "id": "brOX0rqxBWx8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    ")\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ],
   "metadata": {
    "id": "ozM8DI68BltZ"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# template 활용법 1 - 입력 변수\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt)\n",
    "print()\n",
    "print(prompt.format(country=\"대한민국\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lR4ButsfBv3z",
    "outputId": "cb60b834-0396-4743-fac8-8c91429561a0"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input_variables=['country'] input_types={} partial_variables={} template='{country}의 수도는 어디인가요?'\n",
      "\n",
      "대한민국의 수도는 어디인가요?\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# template 활용법 2 - 부분 변수 채움\n",
    "template = \"{country1}과 {country2}의 수도는 각각 어디인가요?\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country1\"],\n",
    "    partial_variables={\n",
    "        \"country2\": \"미국\"  # dictionary 형태로 partial_variables를 전달\n",
    "    },\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "print(prompt.format(country1=\"한국\"))\n",
    "print()\n",
    "\n",
    "prompt_partial = prompt.partial(country2=\"일본\")\n",
    "print(prompt_partial)\n",
    "print(prompt_partial.format(country1=\"한국\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGzuF4DVByHZ",
    "outputId": "c2a059cd-8829-4115-ed2f-5dcf4d696f24"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input_variables=['country1'] input_types={} partial_variables={'country2': '미국'} template='{country1}과 {country2}의 수도는 각각 어디인가요?'\n",
      "한국과 미국의 수도는 각각 어디인가요?\n",
      "\n",
      "input_variables=['country1'] input_types={} partial_variables={'country2': '일본'} template='{country1}과 {country2}의 수도는 각각 어디인가요?'\n",
      "한국과 일본의 수도는 각각 어디인가요?\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# template 활용법 3 - 부분 변수 채움 & 함수\n",
    "def get_today():\n",
    "    \"\"\"오늘 날짜 출력 함수\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%b-%d\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        \"today\": get_today  # dictionary 형태로 partial_variables를 전달\n",
    "    },\n",
    ")\n",
    "\n",
    "print(prompt.format(n=3))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH8wD4UaCQcZ",
    "outputId": "540f312f-004d-41f9-d48b-75bbb1f9f017"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "오늘의 날짜는 Mar-15 입니다. 오늘이 생일인 유명인 3명을 나열해 주세요. 생년월일을 표기해주세요.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# template 활용법 4 - Chat & MessagePlaceholder\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "    ],\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcdk_G5NCZWK",
    "outputId": "ecf59ee3-2061-4c6a-853b-1475fe0d7bbf"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "System: 당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\n",
      "Human: 안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\n",
      "AI: 반가워요! 앞으로 잘 부탁 드립니다.\n",
      "Human: 지금까지의 대화를 5 단어로 요약합니다.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.2 Generation - 검색 결과와 프롬프트 결합 실습"
   ],
   "metadata": {
    "id": "DBPaHr39FjYZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.prompts import format_document\n",
    "\n",
    "\n",
    "# retriever 옵션 설정\n",
    "retriever = store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 4,\n",
    "        \"fetch_k\": 10,\n",
    "        \"lambda_mult\": 0.5\n",
    "    },\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    # \"당신은 질의 응답 업무의 보조자 입니다.\"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    # \"검색된 다음 컨텍스트 를 사용 하여 질문에 응답 하십시오.\"\n",
    "    \"If you don't know the answer, say that you don't know.\"\n",
    "    # \"답을 모르면 모른다고 하세요\"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    # \"최대 세 문장을 사용하고 답을 간결하게 유지합니다.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\\n\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 검색 결과에 사용할 template\n",
    "docs_prompt = PromptTemplate.from_template(\n",
    "    \"page_content:\\n{page_content}\\n\"\n",
    ")\n",
    "\n",
    "def format_docs(inputs: dict) -> str:\n",
    "    return \"\\n\".join(format_document(doc, docs_prompt) for doc in inputs[\"context\"])\n",
    "\n",
    "\n",
    "stuff_format = (\n",
    "    RunnablePassthrough.assign(**{\"context\": format_docs}).with_config(\n",
    "        run_name=\"format_inputs\"\n",
    "    )\n",
    "    | prompt\n",
    ").with_config(run_name=\"stuff_format\")\n",
    "\n",
    "rag_prompt_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_format,\n",
    "    ).assign(**{\"prompt\": stuff_format})\n",
    "\n",
    "results = rag_prompt_chain.invoke({\"input\": \"Embodied 에 대한 정보를 자료를 기반으로 설명해줘\"})\n",
    "\n",
    "print(results['prompt'].to_string())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJzCHWRfFiOG",
    "outputId": "d95b23ba-e3fe-4ec2-84b8-bab7e2a02d7d"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "System: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.If you don't know the answer, say that you don't know.Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "page_content:\n",
      "이처럼 Embodied AI는 실제 환경에서 경험을 쌓으며 더욱 똑똑해지고 유연해진다.\n",
      "④ 왜 중요한가?\n",
      "Embodied AI의 중요성은 AI가 현실 세계에 더 가까워진다는 점에 있다. 이는 마치 책으로만 공부하던 학생이 \n",
      "실제 현장에서 경험을 쌓는 것과 같다. 이를 통해 AI는 더 실용적이고 유연한 능력을 갖출 수 있다.\n",
      "예를 들어, 재난 현장에서 활동하는 구조 로봇을 생각해보자. 이 로봇은 실제 재난 현장의 불규칙한 지형, 예측 \n",
      "불가능한 상황 등을 직접 경험하며 학습한다. 이런 경험을 통해 로봇은 더 효과적으로 인명을 구조하고 위험을 \n",
      "감지할 수 있게 된다.\n",
      "또한 Embodied AI는 인간과 AI의 상호작용을 더욱 자연스럽게 만든다. 예를 들어, 노인 돌봄 로봇은 실제 \n",
      "노인들과 대화하고 교감하면서 더 섬세하고 인간적인 돌봄 서비스를 제공할 수 있게 된다.\n",
      "⑤ 어디에 활용되는가?\n",
      "Embodied AI는 우리 생활 곳곳에서 활용될 수 있다:\n",
      "Ÿ 가정: 로봇 청소기뿐만 아니라 요리, 빨래, 설거지 등을 돕는 가사 도우미 로봇으로 활용된다.\n",
      "\n",
      "page_content:\n",
      "기존의 AI는 주로 컴퓨터 안에서만 존재하며 데이터를 분석하고 결과를 내놓았다. 이는 마치 책만 보고 세상을 \n",
      "배우는 것과 같다. 하지만 실제 세상은 책에 나오는 것보다 훨씬 복잡하고 예측하기 어렵다.\n",
      "예를 들어, 자율주행차가 도로에서 마주치는 상황은 매번 다르다. 갑자기 뛰어드는 동물, 예기치 못한 공사 \n",
      "현장, 날씨 변화 등 수많은 변수가 있다. 이런 상황에서 AI가 효과적으로 대응하려면 실제 환경과 상호작용하며 \n",
      "학습하고 적응하는 능력이 필요하다. 이런 필요성에 의해 Embodied AI가 탄생했다.\n",
      "② 쉽게 설명하면?\n",
      "Embodied AI는 말 그대로 ‘몸을 가진 AI’이다. 이는 로봇, 드론, 자율주행차 등 물리적인 형태를 가진 AI \n",
      "시스템을 말한다. 이들은 마치 우리 인간처럼 감각 기관(센서)으로 주변을 인식하고, 뇌(AI 알고리듬)로 상황을 \n",
      "판단하며, 근육(모터 등)을 움직여 행동한다.\n",
      "25) 골드만삭스 “10년 뒤 휴머노이드 연간 100만대 이상 생산” (임대준, 골드만삭스 “10년 뒤 휴머노이드 연간 100만대 이상 \n",
      "생산”, 2024)\n",
      "26) ‘AI 끝판왕’ 휴머노이드…인간처럼 ‘촉감’ 가진 로봇 5년내 나온다 (이해성강경주, 2024)\n",
      "\n",
      "page_content:\n",
      "4. Embodied AI 구현 기술\n",
      "4.1. 주의집중 메커니즘 (Attention Mechanism): AI의 감각과 인지 능력 향상, 세상을 더욱 깊이 \n",
      "이해하다\n",
      "① 왜 나오게 되었는가?\n",
      "주의집중 메커니즘은 AI가 인간처럼 ‘맥락에 맞춰 중요한 정보에 집중’할 수 있도록 만들기 위해 탄생했다. 초기의 \n",
      "AI는 마치 갓 태어난 아기처럼, 주변의 모든 감각 정보를 똑같이 중요하게 여겼다. 예를 들어, Embodied AI 로봇\n",
      "이 방 안을 돌아다닐 때, 벽의 질감, 바닥의 먼지, 창문 밖 풍경 등 모든 정보를 동일하게 처리했다. 하지만 인간은 \n",
      "상황에 따라 중요한 정보에 집중한다. 길을 찾을 때는 주변 지형지물에, 대화할 때는 상대방의 표정과 목소리에 더 \n",
      "주목한다. AI도 이렇게 할 수 있다면 더 효율적으로 세상을 이해하고 상호작용할 수 있을 것이라는 생각에서 주의\n",
      "집중 메커니즘이 개발되었다.\n",
      "② 쉽게 설명하면?\n",
      "주의집중 메커니즘은 AI에게 ‘선택과 집중’의 능력을 부여하는 기술이다. 이는 마치 숲속에서 길을 잃었을 때 나침\n",
      "반을 보며 방향을 찾는 것과 같다. 나침반은 우리에게 북쪽이 어디인지 알려주어 불필요한 방황을 줄여준다. 주의집중 \n",
      "메커니즘은 AI에게 이런 나침반 역할을 한다. 예를 들어, 자율주행 자동차가 복잡한 도로에서 주변 차량, 보행자, \n",
      "신호등 등 중요한 정보에 집중하게 하거나, Embodied AI 로봇이 물체를 잡을 때 물체의 모양, 크기, 위치 등에 \n",
      "집중하게 한다. 이를 통해 AI는 불필요한 정보는 걸러내고 중요한 정보에만 집중하여 더 효율적으로 작업을 수행할 \n",
      "수 있게 된다.\n",
      "\n",
      "page_content:\n",
      "4.3. 멀티모달 퓨전 (Multimodal Fusion): 인공지능의 오감 통합, 더욱 풍부한 세상 이해를 위한 열쇠\n",
      "① 왜 나오게 되었는가?\n",
      "멀티모달 퓨전은 Embodied AI에게 ‘오감’을 주기 위해 탄생했다. 로봇이나 자율주행차와 같은 Embodied \n",
      "AI는 실제 환경에서 작동하며, 다양한 센서를 통해 환경과 상호작용한다. 하지만 초기의 Embodied AI는 마\n",
      "치 한 가지 감각만 가진 존재처럼 제한적으로 정보를 처리했다. 이런 한계를 극복하고 Embodied AI가 인간\n",
      "처럼 다양한 정보를 종합적으로 이해할 수 있도록 멀티모달 퓨전 기술이 개발되었다. 이는 Embodied AI가 \n",
      "복잡하고 역동적인 실제 환경에 더욱 효과적으로 대응할 수 있게 해준다.\n",
      "② 쉽게 설명하면?\n",
      "멀티모달 퓨전은 Embodied AI가 ‘여러 가지 센서 정보를 동시에 고려하여 환경을 이해하는 능력’이라고 할 \n",
      "수 있다. 이는 마치 요리사가 여러 가지 재료를 조화롭게 섞어 맛있는 요리를 만드는 것과 비슷하다. \n",
      "Embodied AI는 카메라(시각), 마이크(청각), 압력 센서(촉각) 등 다양한 센서 데이터를 ‘재료’로 사용하여 더 \n",
      "정확하고 풍부한 ‘요리(환경 이해)’를 만들어낸다. 예를 들어, 자율주행차는 카메라, 라이다, 레이더 등의 정보를 \n",
      "종합하여 주변 환경을 더욱 정확하게 파악할 수 있다.\n",
      "③ 예시와 함께 좀 더 자세히 알아볼까?\n",
      "멀티모달 퓨전의 실제 활용 사례를 살펴보자:\n",
      "Ÿ 서비스 로봇: 서비스 로봇은 멀티모달 퓨전을 활용하여 사용자와 더 자연스럽게 상호작용한다. 예를 들\n",
      "어, 사용자가 “저기 있는 빨간 컵 좀 가져다 주세요”라고 말하면, 로봇은 음성 명령(청각), 사용자의 시선\n",
      "\n",
      "\n",
      "Human: Embodied 에 대한 정보를 자료를 기반으로 설명해줘\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.3 Generation - LLM API 연결 실습"
   ],
   "metadata": {
    "id": "gGKtvLjpKCt6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain_openai"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "QIVK7RevJt4M",
    "outputId": "70995e5c-d097-4255-852f-7fa5fa463a76"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.44)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
      "Downloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.4/55.4 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m58.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tiktoken, langchain_openai\n",
      "Successfully installed langchain_openai-0.3.8 tiktoken-0.9.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"{키입력}\"  # 생성한 api 키"
   ],
   "metadata": {
    "id": "ZyEQ9ouhKfkX"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "LLM_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "LLM_TEMPERATURE = 0\n",
    "\n",
    "model = ChatOpenAI(\n",
    "  temperature=LLM_TEMPERATURE,  # 창의성\n",
    "  model_name=LLM_MODEL_NAME,  # 모델명\n",
    ")"
   ],
   "metadata": {
    "id": "ZeUgihHPKAvO"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = model.invoke(\"Embodied 에 대한 정보를 자료를 기반으로 설명해줘\")\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f37SnNjuKPHq",
    "outputId": "32266376-e154-4f15-b015-0790a7a6f653"
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content='Embodied는 물리적인 존재나 형태를 가진다는 의미로 사용되는 용어입니다. 이 용어는 주로 신체적인 경험과 감각을 강조하는 맥락에서 사용됩니다. 예를 들어, \"embodied cognition\"은 인간의 사고와 지식이 신체적 경험과 상호작용을 통해 형성된다는 이론을 가리킵니다.\\n\\nEmbodied cognition 이론은 인간의 사고 과정이 단순히 뇌의 활동에 의해 결정되는 것이 아니라, 신체적 경험과 감각, 환경과의 상호작용 등이 모두 영향을 미치는 것으로 보는 관점을 제시합니다. 이는 우리가 세상을 이해하고 상호작용하는 방식이 우리의 신체적 경험과 감각에 근거한다는 것을 강조하는 것입니다.\\n\\n또한, embodied는 물리적인 형태를 가진다는 의미로도 사용됩니다. 예를 들어, \"embodied robot\"은 실제로 물리적인 몸체를 가지고 활동하는 로봇을 가리킵니다. 이러한 로봇은 주변 환경과 상호작용하며 일상 생활에서 다양한 작업을 수행할 수 있습니다.\\n\\n종합하면, embodied는 신체적 경험과 감각을 강조하거나 물리적 형태를 가진 것을 의미하는 용어로 다양한 분야에서 사용되고 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 460, 'prompt_tokens': 26, 'total_tokens': 486, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-bfe9daec-d429-4d44-b89c-8e8d5c44759e-0' usage_metadata={'input_tokens': 26, 'output_tokens': 460, 'total_tokens': 486, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "chain = model | StrOutputParser()\n",
    "result = chain.invoke(\"Embodied 에 대한 정보를 자료를 기반으로 설명해줘\")\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8NdCS_PLTZu",
    "outputId": "27851c68-7b00-4f12-f0ce-2cec6244735c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embodied는 물리적인 존재나 형태를 가진다는 의미로 사용되는 용어입니다. 이 용어는 주로 신체적인 경험과 감각을 강조하는 맥락에서 사용됩니다. 예를 들어, \"embodied cognition\"은 인간의 사고와 인식이 신체적 경험과 상호작용에 의해 형성된다는 이론을 가리킵니다.\n",
      "\n",
      "Embodied cognition 이론은 인간의 사고 과정이 단순히 뇌의 활동에 의해만 형성되는 것이 아니라, 신체적 경험과 감각, 환경과의 상호작용 등이 모두 영향을 미치는 것으로 보고합니다. 이는 우리가 세상을 이해하고 상호작용하는 방식이 우리의 신체적 경험과 감각에 근거한다는 것을 의미합니다.\n",
      "\n",
      "또한, embodied는 신체적인 형태나 존재를 강조하는 것으로도 사용됩니다. 예를 들어, \"embodied robot\"은 물리적인 로봇이나 기계를 가리키며, \"embodied language\"는 언어가 신체적인 동작이나 행동과 연관되어 있는 것을 의미할 수 있습니다.\n",
      "\n",
      "종합하면, embodied는 신체적 경험과 감각, 물리적 형태와 존재를 강조하는 용어로 다양한 분야에서 사용되고 있습니다.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.4 Generation - RAG 실습"
   ],
   "metadata": {
    "id": "ZMsBKX3ILpAM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=stuff_format | model | StrOutputParser(),\n",
    ").assign(**{\"prompt\": stuff_format})\n",
    "\n",
    "result = rag_chain.invoke({\"input\": \"Embodied 에 대한 정보를 자료를 기반으로 설명해줘\"})\n",
    "print(result[\"answer\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4USFkAEoLuDE",
    "outputId": "b6cb785b-78ff-4bab-e7a5-2d5a04ff6c81"
   },
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embodied AI는 실제 환경에서 경험을 쌓으며 AI가 더욱 똑똑하고 유연해지는 기술을 말합니다. 이는 마치 책으로만 공부하는 것이 아니라 실제 경험을 통해 학습하는 것과 유사합니다. Embodied AI는 로봇이나 자율주행차와 같은 물리적 형태를 가진 AI 시스템을 포함하며, 주변을 감지하고 판단하여 행동할 수 있게 합니다.\n"
     ]
    }
   ]
  }
 ]
}
